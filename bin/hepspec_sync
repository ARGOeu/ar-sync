#!/bin/env python

# Copyright (c) 2013 GRNET S.A., SRCE, IN2P3 CNRS Computing Centre
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the
# License. You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing,
# software distributed under the License is distributed on an "AS
# IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either
# express or implied. See the License for the specific language
# governing permissions and limitations under the License.
# 
# The views and conclusions contained in the software and
# documentation are those of the authors and should not be
# interpreted as representing official policies, either expressed
# or implied, of either GRNET S.A., SRCE or IN2P3 CNRS Computing
# Centre
# 
# The work represented by this source file is partially funded by
# the EGI-InSPIRE project through the European Commission's 7th
# Framework Programme (contract # INFSO-RI-261323) 

import urllib
import urllib2
import os
import json
import datetime
import httplib
import sys
import urlparse

defaultOutputDir = '/var/lib/ar-sync'

defaultOutputFile = defaultOutputDir + '/hepspec_sync_%s.out'
defaultOutputFileFieldFormat = '%s\001%s\r\n'
defaultGstatRequest = 'http://gstat2.grid.sinica.edu.tw/gstat/summary/json/'

##############################
# create output filename
##############################
def createOutputFilename(timestamp):
	return defaultOutputFile % timestamp

##############################
# load name mapping
##############################
def loadOldData(filename):

        oldDataDict = dict()

        oldDataFile = open(filename, 'r')
        oldData = oldDataFile.read().splitlines()
        oldDataFile.close();

        for line in oldData:
                if len(line) == 0 or line[0] == '#':
                        continue

                oldDataFields = line.split('\001')
                if len(oldDataFields) > 1:
                        key = oldDataFields[0].strip()
                        val = int(oldDataFields[1].strip())
                        oldDataDict[key] = val

        return oldDataDict

##############################
# main
##############################

timestamp = datetime.datetime.utcnow().strftime('%Y_%m_%d')
newFilename = createOutputFilename(timestamp)

oldDate = datetime.datetime.utcnow()
oldFilename = createOutputFilename(oldDate.strftime('%Y_%m_%d'))

# find old data
i = 0;
oldDataExists = True
while not os.path.isfile(oldFilename):
	oldDate = oldDate - datetime.timedelta(days=1)
	oldFilename = createOutputFilename(oldDate.strftime('%Y_%m_%d'))
	i = i+1
	if i >= 30:
		oldDataExists = False
		break

#load old data
if oldDataExists:
	oldData = loadOldData(oldFilename)
else:
	oldData = dict()

# load server data
urlFile = urllib2.urlopen(defaultGstatRequest)
json_data = json.load(urlFile)
urlFile.close();

# fill new list
newData = dict()
for site in json_data:
	key = site['Sitename']
	newVal = int(site['HEPSPEC06'])
	if newVal <= 0:
		if key in oldData:
			newVal = oldData[key]
	if key not in oldData:
		oldData[key] = newVal
	newData[key] = newVal

# fill old list
for key in oldData:
	oldVal = oldData[key]
	if oldVal <= 0:
                if key in newData:
                        oldData[key] = newData[key]
	if key not in newData:
		newData[key] = oldData[key]

# write output
newOutputFile = open(newFilename, 'w')
if oldDataExists:
	if oldFilename == newFilename:
		oldDataExists = False
	else:
		oldOutputFile = open(oldFilename, 'w')

for key in newData:
	newOutputFile.write(defaultOutputFileFieldFormat % (key, newData[key]))
	if oldDataExists:
		oldOutputFile.write(defaultOutputFileFieldFormat % (key, oldData[key]))
	
newOutputFile.close()
if oldDataExists:
	oldOutputFile.close()	

